{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define input data loading functions - TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on https://www.tensorflow.org/tutorials/load_data/images#using_tfdata_for_finer_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class names get turned into 0, 1, 2, 3, ... to be used with sparse_categorical_crossentropy\n",
    "def encode_class_label(class_name, available_classes):\n",
    "  numerical_label = class_name == available_classes\n",
    "  return tf.argmax(numerical_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode png\n",
    "def decode_img_data(img_data, channels=3):\n",
    "  img_data = tf.io.decode_png(img_data, channels=channels)\n",
    "  return tf.image.resize(img_data, [IMAGE_SIZE, IMAGE_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return pair: decoded png and class name turned into numerical label\n",
    "def process_sample(sample, available_classes, channels=3):\n",
    "  img_path = sample[0]\n",
    "  class_label = sample[1]\n",
    "  \n",
    "  img_data = tf.io.read_file(img_path)\n",
    "  img_data = decode_img_data(img_data, channels)\n",
    "  numerical_label = one_hot_encode_class_label(class_label, available_classes)\n",
    "  return img_data, numerical_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance(ds, batch_size=8):\n",
    "  ds = ds.cache()\n",
    "  ds = ds.shuffle(buffer_size=1000)\n",
    "  ds = ds.batch(batch_size)\n",
    "  ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path&genre pairs from dataframe -> image data&numerically-encoded label pairs as dataset\n",
    "def prepare_dataset_based_on_df(df, available_classes, batch_size=8, channels=3):\n",
    "    df.loc[:, 'path'] = df['path'].apply(lambda x: str(x)) # copy-on-write warning fixed with the loc\n",
    "    ds = tf.data.Dataset.from_tensor_slices((df['path'], df['genre']))\n",
    "    \n",
    "    print(\"Example data:\")\n",
    "    [print(d[0].numpy(), d[1].numpy()) for d in ds.take(3)]\n",
    "        \n",
    "    print(f'Data set size: {tf.data.experimental.cardinality(ds).numpy()}')    \n",
    "    \n",
    "    # Use Dataset.map to create a Dataset of (image data, numerically-encoded label) pairs:\n",
    "    ds = ds.map(lambda *d: process_sample(d, available_classes, channels),\n",
    "                num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    ds = configure_for_performance(ds, batch_size)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples_from_dataset_batch(ds, available_classes, samples=6):\n",
    "    image_batch, label_batch = next(iter(ds))\n",
    "    samples = samples if samples <= len(label_batch) else len(label_batch)\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=3, nrows=(samples + 2) // 3)\n",
    "    [axis.set_axis_off() for axis in axes.ravel()]\n",
    "    \n",
    "    for i in range(samples):\n",
    "        ax = axes.flat[i]\n",
    "        ax.imshow(image_batch[i].numpy().astype(\"uint8\"))\n",
    "        ax.set_title(available_classes[label_batch[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic - but with no manual control over the split\n",
    "#\n",
    "# gtzan_image_dir = gtzan_dir / 'spectrograms'\n",
    "# gtzan_train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#   gtzan_image_dir,\n",
    "#   seed=42,\n",
    "#   validation_split=0.2,\n",
    "#   labels='inferred',\n",
    "#   label_mode='categorical',\n",
    "#   color_mode='rgb',\n",
    "#   image_size=(IMAGE_SIZE, IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN(img_size, channels, num_classes):\n",
    "    return models.Sequential([\n",
    "        layers.Input(shape=(img_size, img_size, channels)),\n",
    "        \n",
    "        layers.Conv2D(64, (5, 5), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Conv2D(64, (5, 5), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Conv2D(128, (5, 5), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Conv2D(128, (5, 5), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_metrics=[tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "                    #...\n",
    "                ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/Testing - TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gtzan = create_CNN(img_size=IMAGE_SIZE, channels=CHANNELS, num_classes=len(gtzan_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gtzan.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=multiclass_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gtzan.fit(\n",
    "  gtzan_train_dl,\n",
    "  validation_data=gtzan_val_dl,\n",
    "  epochs=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gtzan.evaluate(\n",
    "  gtzan_test_dl\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
